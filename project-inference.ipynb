{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# About this notebook\n- Deberta-v3-base starter code\n- pip wheels is [here](https://www.kaggle.com/code/yasufuminakama/fb3-pip-wheels)\n- Training notebook is [here](https://www.kaggle.com/code/yasufuminakama/fb3-deberta-v3-base-baseline-train)\n\nIf this notebook is helpful, feel free to upvote :)","metadata":{"papermill":{"duration":0.02594,"end_time":"2022-02-08T11:42:51.890919","exception":false,"start_time":"2022-02-08T11:42:51.864979","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# CFG","metadata":{"papermill":{"duration":0.026525,"end_time":"2022-02-08T11:42:51.944085","exception":false,"start_time":"2022-02-08T11:42:51.91756","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    num_workers=4\n#     path=\"../input/fb3-deberta-v3-base-baseline-train/\"\n    path=\"/kaggle/input/project-ew-train/\"\n    config_path=path+'config.pth'\n    model=\"microsoft/deberta-v3-base\"\n    gradient_checkpointing=False\n    batch_size=24\n    target_cols=['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions']\n    seed=42\n    n_fold=4\n    trn_fold=[0, 1, 2, 3]","metadata":{"papermill":{"duration":0.031276,"end_time":"2022-02-08T11:42:51.991958","exception":false,"start_time":"2022-02-08T11:42:51.960682","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-06T00:17:45.775024Z","iopub.execute_input":"2024-05-06T00:17:45.775533Z","iopub.status.idle":"2024-05-06T00:17:45.782964Z","shell.execute_reply.started":"2024-05-06T00:17:45.775486Z","shell.execute_reply":"2024-05-06T00:17:45.781551Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Library","metadata":{"papermill":{"duration":0.015324,"end_time":"2022-02-08T11:42:52.022769","exception":false,"start_time":"2022-02-08T11:42:52.007445","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# Library\n# ====================================================\nimport os\nimport gc\nimport re\nimport ast\nimport sys\nimport copy\nimport json\nimport time\nimport math\nimport string\nimport pickle\nimport random\nimport joblib\nimport itertools\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\nfrom tqdm.auto import tqdm\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import Parameter\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD, AdamW\nfrom torch.utils.data import DataLoader, Dataset\n\nos.system('pip uninstall -y transformers')\nos.system('pip uninstall -y tokenizers')\nos.system('python -m pip install --no-index --find-links=../input/fb3-pip-wheels transformers')\nos.system('python -m pip install --no-index --find-links=../input/fb3-pip-wheels tokenizers')\nimport tokenizers\nimport transformers\nprint(f\"tokenizers.__version__: {tokenizers.__version__}\")\nprint(f\"transformers.__version__: {transformers.__version__}\")\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig\nfrom transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\nfrom transformers import DataCollatorWithPadding\n%env TOKENIZERS_PARALLELISM=false\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"papermill":{"duration":19.692613,"end_time":"2022-02-08T11:43:11.730777","exception":false,"start_time":"2022-02-08T11:42:52.038164","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-06T00:14:06.768965Z","iopub.execute_input":"2024-05-06T00:14:06.769349Z","iopub.status.idle":"2024-05-06T00:14:36.193698Z","shell.execute_reply.started":"2024-05-06T00:14:06.769316Z","shell.execute_reply":"2024-05-06T00:14:36.192744Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Found existing installation: transformers 4.21.2\nUninstalling transformers-4.21.2:\n  Successfully uninstalled transformers-4.21.2\n","output_type":"stream"},{"name":"stderr","text":"WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n","output_type":"stream"},{"name":"stdout","text":"Found existing installation: tokenizers 0.12.1\nUninstalling tokenizers-0.12.1:\n  Successfully uninstalled tokenizers-0.12.1\n","output_type":"stream"},{"name":"stderr","text":"WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n","output_type":"stream"},{"name":"stdout","text":"Looking in links: ../input/fb3-pip-wheels\nProcessing /kaggle/input/fb3-pip-wheels/transformers-4.21.2-py3-none-any.whl\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.7.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.8.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.28.1)\nProcessing /kaggle/input/fb3-pip-wheels/tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.12.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.3.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.8.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.12)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.3)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.1.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.6.15)\nInstalling collected packages: tokenizers, transformers\n","output_type":"stream"},{"name":"stderr","text":"ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nallennlp 2.10.0 requires protobuf==3.20.0, but you have protobuf 3.19.4 which is incompatible.\nallennlp 2.10.0 requires transformers<4.21,>=4.1, but you have transformers 4.21.2 which is incompatible.\nWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n","output_type":"stream"},{"name":"stdout","text":"Successfully installed tokenizers-0.12.1 transformers-4.21.2\nLooking in links: ../input/fb3-pip-wheels\nRequirement already satisfied: tokenizers in /opt/conda/lib/python3.7/site-packages (0.12.1)\n","output_type":"stream"},{"name":"stderr","text":"WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n","output_type":"stream"},{"name":"stdout","text":"tokenizers.__version__: 0.12.1\ntransformers.__version__: 4.21.2\nenv: TOKENIZERS_PARALLELISM=false\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# tokenizer","metadata":{"papermill":{"duration":0.017982,"end_time":"2022-02-08T11:43:11.767286","exception":false,"start_time":"2022-02-08T11:43:11.749304","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# tokenizer\n# ====================================================\nCFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')","metadata":{"papermill":{"duration":0.17588,"end_time":"2022-02-08T11:43:11.961555","exception":false,"start_time":"2022-02-08T11:43:11.785675","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-06T00:17:49.688973Z","iopub.execute_input":"2024-05-06T00:17:49.689367Z","iopub.status.idle":"2024-05-06T00:17:49.943153Z","shell.execute_reply.started":"2024-05-06T00:17:49.689332Z","shell.execute_reply":"2024-05-06T00:17:49.942081Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Utils","metadata":{"papermill":{"duration":0.017596,"end_time":"2022-02-08T11:43:12.141759","exception":false,"start_time":"2022-02-08T11:43:12.124163","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# Utils\n# ====================================================\ndef MCRMSE(y_trues, y_preds):\n    scores = []\n    idxes = y_trues.shape[1]\n    for i in range(idxes):\n        y_true = y_trues[:,i]\n        y_pred = y_preds[:,i]\n        score = mean_squared_error(y_true, y_pred, squared=False) # RMSE\n        scores.append(score)\n    mcrmse_score = np.mean(scores)\n    return mcrmse_score, scores\n\n\ndef get_score(y_trues, y_preds):\n    mcrmse_score, scores = MCRMSE(y_trues, y_preds)\n    return mcrmse_score, scores\n\n\ndef get_logger(filename='inference'):\n    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=f\"{filename}.log\")\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = get_logger()\n\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_everything(seed=42)","metadata":{"papermill":{"duration":0.030498,"end_time":"2022-02-08T11:43:12.189984","exception":false,"start_time":"2022-02-08T11:43:12.159486","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-06T00:17:52.816358Z","iopub.execute_input":"2024-05-06T00:17:52.816780Z","iopub.status.idle":"2024-05-06T00:17:52.832335Z","shell.execute_reply.started":"2024-05-06T00:17:52.816745Z","shell.execute_reply":"2024-05-06T00:17:52.831487Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# OOF","metadata":{"papermill":{"duration":0.01765,"end_time":"2022-02-08T11:43:12.225407","exception":false,"start_time":"2022-02-08T11:43:12.207757","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# oof\n# ====================================================\noof_df = pd.read_pickle(CFG.path+'oof_df.pkl')\nlabels = oof_df[CFG.target_cols].values\npreds = oof_df[[f\"pred_{c}\" for c in CFG.target_cols]].values\nscore, scores = get_score(labels, preds)\nLOGGER.info(f'Score: {score:<.4f}  Scores: {scores}')","metadata":{"papermill":{"duration":42.093803,"end_time":"2022-02-08T11:43:54.337033","exception":false,"start_time":"2022-02-08T11:43:12.24323","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-06T00:17:55.355410Z","iopub.execute_input":"2024-05-06T00:17:55.356378Z","iopub.status.idle":"2024-05-06T00:17:55.437933Z","shell.execute_reply.started":"2024-05-06T00:17:55.356333Z","shell.execute_reply":"2024-05-06T00:17:55.437044Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"Score: 0.4629  Scores: [0.49996912544244104, 0.4515330718968534, 0.4193498899172248, 0.46073638431955016, 0.48477918584793567, 0.46078207798876714]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Data Loading","metadata":{"papermill":{"duration":0.021365,"end_time":"2022-02-08T11:43:54.379768","exception":false,"start_time":"2022-02-08T11:43:54.358403","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# Data Loading\n# ====================================================\nfrom sklearn.model_selection import train_test_split\ndata = pd.read_csv('../input/feedback-prize-english-language-learning/train.csv')\ntrain, test = train_test_split(data, test_size=0.2, random_state=42)\ntrain.reset_index(drop=True, inplace=True)\ntest.reset_index(drop=True, inplace=True)\nsubmission = pd.read_csv('../input/feedback-prize-english-language-learning/sample_submission.csv')\n\nprint(f\"test.shape: {test.shape}\")\ndisplay(test.head())\nprint(f\"submission.shape: {submission.shape}\")\ndisplay(submission.head())","metadata":{"execution":{"iopub.status.busy":"2024-05-06T00:17:59.562604Z","iopub.execute_input":"2024-05-06T00:17:59.563531Z","iopub.status.idle":"2024-05-06T00:17:59.772686Z","shell.execute_reply.started":"2024-05-06T00:17:59.563496Z","shell.execute_reply":"2024-05-06T00:17:59.771700Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"test.shape: (783, 8)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"        text_id                                          full_text  cohesion  syntax  vocabulary  phraseology  grammar  conventions\n0  772D27D400BB  It god to have a possitive attitude when you d...       3.0     2.5         2.5          2.0      2.0          2.0\n1  9E8F3C6405CA  Why do people ask more then one person for adv...       3.0     2.0         3.0          3.5      3.0          3.0\n2  948771F795EB  We accomplish more when we are active, and are...       4.0     4.0         3.0          4.0      4.0          4.0\n3  FE14D7378CFB  Do you agree or disagree about imagination bei...       3.0     3.0         3.5          3.0      3.5          3.5\n4  7AAE019F70D6  I disagree with the principal saying that all ...       3.5     3.5         3.5          3.5      3.0          3.5","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_id</th>\n      <th>full_text</th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>772D27D400BB</td>\n      <td>It god to have a possitive attitude when you d...</td>\n      <td>3.0</td>\n      <td>2.5</td>\n      <td>2.5</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>9E8F3C6405CA</td>\n      <td>Why do people ask more then one person for adv...</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>948771F795EB</td>\n      <td>We accomplish more when we are active, and are...</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>FE14D7378CFB</td>\n      <td>Do you agree or disagree about imagination bei...</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>3.5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7AAE019F70D6</td>\n      <td>I disagree with the principal saying that all ...</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>3.5</td>\n      <td>3.0</td>\n      <td>3.5</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}},{"name":"stdout","text":"submission.shape: (3, 7)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"        text_id  cohesion  syntax  vocabulary  phraseology  grammar  conventions\n0  0000C359D63E       3.0     3.0         3.0          3.0      3.0          3.0\n1  000BAD50D026       3.0     3.0         3.0          3.0      3.0          3.0\n2  00367BB2546B       3.0     3.0         3.0          3.0      3.0          3.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_id</th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0000C359D63E</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>000BAD50D026</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00367BB2546B</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# sort by length to speed up inference\ntest['tokenize_length'] = [len(CFG.tokenizer(text)['input_ids']) for text in test['full_text'].values]\ntest = test.sort_values('tokenize_length', ascending=True).reset_index(drop=True)\ndisplay(test.head())","metadata":{"execution":{"iopub.status.busy":"2024-05-06T00:18:02.009763Z","iopub.execute_input":"2024-05-06T00:18:02.010155Z","iopub.status.idle":"2024-05-06T00:18:03.233411Z","shell.execute_reply.started":"2024-05-06T00:18:02.010120Z","shell.execute_reply":"2024-05-06T00:18:03.232345Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"        text_id                                          full_text  cohesion  syntax  vocabulary  phraseology  grammar  conventions  tokenize_length\n0  BA14C47026ED  The principal is considering changing school p...       2.0     2.0         2.5          1.5      2.5          2.5               83\n1  72766FE38307  dear principal i think they should help to do ...       2.5     2.0         2.5          2.0      2.5          2.5               96\n2  CBDE3C526D05  Dear, Principal\\r\\n\\r\\nI think your students s...       2.5     1.5         3.0          2.0      2.5          2.5              105\n3  13E1CB9819CB  To who it may concern,\\n\\nHello my name is STU...       3.5     4.0         4.0          4.0      4.5          3.5              112\n4  AEF788DA28DE  I think that the principal should not change t...       3.0     3.0         4.0          3.0      3.0          3.5              130","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text_id</th>\n      <th>full_text</th>\n      <th>cohesion</th>\n      <th>syntax</th>\n      <th>vocabulary</th>\n      <th>phraseology</th>\n      <th>grammar</th>\n      <th>conventions</th>\n      <th>tokenize_length</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>BA14C47026ED</td>\n      <td>The principal is considering changing school p...</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.5</td>\n      <td>1.5</td>\n      <td>2.5</td>\n      <td>2.5</td>\n      <td>83</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>72766FE38307</td>\n      <td>dear principal i think they should help to do ...</td>\n      <td>2.5</td>\n      <td>2.0</td>\n      <td>2.5</td>\n      <td>2.0</td>\n      <td>2.5</td>\n      <td>2.5</td>\n      <td>96</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>CBDE3C526D05</td>\n      <td>Dear, Principal\\r\\n\\r\\nI think your students s...</td>\n      <td>2.5</td>\n      <td>1.5</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>2.5</td>\n      <td>2.5</td>\n      <td>105</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>13E1CB9819CB</td>\n      <td>To who it may concern,\\n\\nHello my name is STU...</td>\n      <td>3.5</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.0</td>\n      <td>4.5</td>\n      <td>3.5</td>\n      <td>112</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>AEF788DA28DE</td>\n      <td>I think that the principal should not change t...</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>3.5</td>\n      <td>130</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Dataset","metadata":{"papermill":{"duration":0.023373,"end_time":"2022-02-08T11:43:55.501283","exception":false,"start_time":"2022-02-08T11:43:55.47791","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# Dataset\n# ====================================================\ndef prepare_input(cfg, text):\n    inputs = cfg.tokenizer.encode_plus(\n        text, \n        return_tensors=None, \n        add_special_tokens=True, \n        #max_length=CFG.max_len,\n        #pad_to_max_length=True,\n        #truncation=True\n    )\n    for k, v in inputs.items():\n        inputs[k] = torch.tensor(v, dtype=torch.long)\n    return inputs\n\n\nclass TestDataset(Dataset):\n    def __init__(self, cfg, df):\n        self.cfg = cfg\n        self.texts = df['full_text'].values\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, item):\n        inputs = prepare_input(self.cfg, self.texts[item])\n        return inputs","metadata":{"papermill":{"duration":0.034236,"end_time":"2022-02-08T11:43:55.55924","exception":false,"start_time":"2022-02-08T11:43:55.525004","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-06T00:18:09.601477Z","iopub.execute_input":"2024-05-06T00:18:09.601868Z","iopub.status.idle":"2024-05-06T00:18:09.610899Z","shell.execute_reply.started":"2024-05-06T00:18:09.601836Z","shell.execute_reply":"2024-05-06T00:18:09.609697Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{"papermill":{"duration":0.023204,"end_time":"2022-02-08T11:43:55.605919","exception":false,"start_time":"2022-02-08T11:43:55.582715","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# Model\n# ====================================================\nclass MeanPooling(nn.Module):\n    def __init__(self):\n        super(MeanPooling, self).__init__()\n        \n    def forward(self, last_hidden_state, attention_mask):\n        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n        sum_mask = input_mask_expanded.sum(1)\n        sum_mask = torch.clamp(sum_mask, min=1e-9)\n        mean_embeddings = sum_embeddings / sum_mask\n        return mean_embeddings\n    \n\nclass CustomModel(nn.Module):\n    def __init__(self, cfg, config_path=None, pretrained=False):\n        super().__init__()\n        self.cfg = cfg\n        if config_path is None:\n            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n            self.config.hidden_dropout = 0.\n            self.config.hidden_dropout_prob = 0.\n            self.config.attention_dropout = 0.\n            self.config.attention_probs_dropout_prob = 0.\n            LOGGER.info(self.config)\n        else:\n            self.config = torch.load(config_path)\n        if pretrained:\n            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n        else:\n            self.model = AutoModel.from_config(self.config)\n        if self.cfg.gradient_checkpointing:\n            self.model.gradient_checkpointing_enable()\n        self.pool = MeanPooling()\n        self.fc = nn.Linear(self.config.hidden_size, 6)\n        self._init_weights(self.fc)\n        \n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, nn.Embedding):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.padding_idx is not None:\n                module.weight.data[module.padding_idx].zero_()\n        elif isinstance(module, nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n        \n    def feature(self, inputs):\n        outputs = self.model(**inputs)\n        last_hidden_states = outputs[0]\n        feature = self.pool(last_hidden_states, inputs['attention_mask'])\n        return feature\n\n    def forward(self, inputs):\n        feature = self.feature(inputs)\n        output = self.fc(feature)\n        return output","metadata":{"papermill":{"duration":0.036876,"end_time":"2022-02-08T11:43:55.666198","exception":false,"start_time":"2022-02-08T11:43:55.629322","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-06T00:18:11.531334Z","iopub.execute_input":"2024-05-06T00:18:11.532170Z","iopub.status.idle":"2024-05-06T00:18:11.549901Z","shell.execute_reply.started":"2024-05-06T00:18:11.532134Z","shell.execute_reply":"2024-05-06T00:18:11.548850Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# inference","metadata":{"papermill":{"duration":0.023567,"end_time":"2022-02-08T11:43:55.713142","exception":false,"start_time":"2022-02-08T11:43:55.689575","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# ====================================================\n# inference\n# ====================================================\ndef inference_fn(test_loader, model, device):\n    preds = []\n    model.eval()\n    model.to(device)\n    tk0 = tqdm(test_loader, total=len(test_loader))\n    for inputs in tk0:\n        for k, v in inputs.items():\n            inputs[k] = v.to(device)\n        with torch.no_grad():\n            y_preds = model(inputs)\n        preds.append(y_preds.to('cpu').numpy())\n    predictions = np.concatenate(preds)\n    return predictions","metadata":{"papermill":{"duration":0.03136,"end_time":"2022-02-08T11:43:55.768189","exception":false,"start_time":"2022-02-08T11:43:55.736829","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-06T00:18:16.998691Z","iopub.execute_input":"2024-05-06T00:18:16.999381Z","iopub.status.idle":"2024-05-06T00:18:17.006586Z","shell.execute_reply.started":"2024-05-06T00:18:16.999348Z","shell.execute_reply":"2024-05-06T00:18:17.005246Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"test_dataset = TestDataset(CFG, test)\ntest_loader = DataLoader(test_dataset,\n                         batch_size=CFG.batch_size,\n                         shuffle=False,\n                         collate_fn=DataCollatorWithPadding(tokenizer=CFG.tokenizer, padding='longest'),\n                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\npredictions = []\nfor fold in CFG.trn_fold:\n    model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n    state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n                       map_location=torch.device('cpu'))\n    model.load_state_dict(state['model'])\n    prediction = inference_fn(test_loader, model, device)\n    predictions.append(prediction)\n    del model, state, prediction; gc.collect()\n    torch.cuda.empty_cache()\npredictions = np.mean(predictions, axis=0)","metadata":{"_kg_hide-output":true,"papermill":{"duration":78.050495,"end_time":"2022-02-08T11:45:13.842076","exception":false,"start_time":"2022-02-08T11:43:55.791581","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-05-06T00:18:19.793282Z","iopub.execute_input":"2024-05-06T00:18:19.794071Z","iopub.status.idle":"2024-05-06T00:21:57.952506Z","shell.execute_reply.started":"2024-05-06T00:18:19.794034Z","shell.execute_reply":"2024-05-06T00:21:57.950906Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/33 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa78ec1ae1de4449bf1bc4d1b27fefcd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/33 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"860b2587aef54d3180051875c0977b57"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/33 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6c1b6946b9a4f55a8349510f02302f9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/33 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7924913f88664ca1b310cd0bfb1c051a"}},"metadata":{}}]},{"cell_type":"markdown","source":"# Submission","metadata":{"papermill":{"duration":0.027753,"end_time":"2022-02-08T11:45:13.90824","exception":false,"start_time":"2022-02-08T11:45:13.880487","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# test[CFG.target_cols] = predictions\n# submission = submission.drop(columns=CFG.target_cols).merge(test[['text_id'] + CFG.target_cols], on='text_id', how='left')\n# display(submission.head())\n# submission[['text_id'] + CFG.target_cols].to_csv('submission.csv', index=False)","metadata":{"papermill":{"duration":0.043913,"end_time":"2022-02-08T11:45:13.979564","exception":false,"start_time":"2022-02-08T11:45:13.935651","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_cols = ['pred_' + col for col in CFG.target_cols]\ntest[pred_cols] = predictions","metadata":{"execution":{"iopub.status.busy":"2024-05-06T00:22:20.398822Z","iopub.execute_input":"2024-05-06T00:22:20.399716Z","iopub.status.idle":"2024-05-06T00:22:20.409835Z","shell.execute_reply.started":"2024-05-06T00:22:20.399679Z","shell.execute_reply":"2024-05-06T00:22:20.408686Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"test.to_csv('./deberta_test_pred.csv')","metadata":{"execution":{"iopub.status.busy":"2024-05-06T00:22:50.776009Z","iopub.execute_input":"2024-05-06T00:22:50.776784Z","iopub.status.idle":"2024-05-06T00:22:50.866937Z","shell.execute_reply.started":"2024-05-06T00:22:50.776748Z","shell.execute_reply":"2024-05-06T00:22:50.866079Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"for col in CFG.target_cols:\n    print(col)\n    MSE = np.mean((test['pred_' + col] - test[col]) ** 2)\n    print('MSE:', MSE)\n    RMSE = np.sqrt(MSE)\n    print('RMSE:', RMSE)\n    MAE = np.mean(np.abs(test['pred_' + col] - test[col]))\n    print('MAE:', MAE)\n    print()","metadata":{"execution":{"iopub.status.busy":"2024-05-06T00:23:10.362640Z","iopub.execute_input":"2024-05-06T00:23:10.363643Z","iopub.status.idle":"2024-05-06T00:23:10.380203Z","shell.execute_reply.started":"2024-05-06T00:23:10.363597Z","shell.execute_reply":"2024-05-06T00:23:10.378978Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"cohesion\nMSE: 0.24208382484621896\nRMSE: 0.49202014678894906\nMAE: 0.3934568213929314\n\nsyntax\nMSE: 0.20283940871198333\nRMSE: 0.4503769629010606\nMAE: 0.3569022885988803\n\nvocabulary\nMSE: 0.18242291818217785\nRMSE: 0.42710996029380754\nMAE: 0.34607157213934536\n\nphraseology\nMSE: 0.20865371513650185\nRMSE: 0.45678629044280855\nMAE: 0.36980355090412903\n\ngrammar\nMSE: 0.2250506562030468\nRMSE: 0.47439504234661517\nMAE: 0.37758202388368806\n\nconventions\nMSE: 0.19967721997525936\nRMSE: 0.44685257073811196\nMAE: 0.3549575490513067\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}